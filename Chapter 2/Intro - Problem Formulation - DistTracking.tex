%% All things Dist. Tracking and Weighted Dist. Tracking
\chapter{Preliminaries}

We first discuss some of the algorithmic and analytical techniques and results necessary to understand the state of the art solutions for solving to the RTS problem and for analysing their performance.

\section{Measuring Algorithm Performance \& Big Oh Notation}

There are goure atomic operations that a CPU can perform: 
\begin{itemize}
    \item \textbf{Regiser (Re-)Initialization}: Set the content of a register to a fixed value, or to the content of another register.
    \item \textbf{Arithmetic Operations}: Take two integers $a$ and $b$ stored in two registers, calculate the following and then store the result in a register
    \item \textbf{Comparison and Branching}: Compare two integers $a$ and $b$ stored in two registers and decide which of the following is true: $a<b, a=b$ abd $a>b$
    \item \textbf{Memory Access}: Take the memory address $p$ stored in a register, then perform one of a read or write operation at adress $p$
\end{itemize}
Every algorithm can be viewed as a sequence of these four atomic operations. The \textit{running time cost} of an algorithm is the measured by the number of operations in the sequence, as a function of the size of the input $n$. The \textit{space consumption} of an algorithm is the measured by the footprint of memory cells which it touches, that is, the peak memory usage when the algorithm is running. We will commonly describe the growth of said function in terms of their Big-$O$ and Big-$\Omega$ complexity defined as follows

\begin{definition}[Big-$O$ Notation]
    We $f(n)$ grows asymptotically no faster than $g(n)$ if there exists two positive constants $c_1$ and $c_2$ such that $f(n)\leq c_1 g(n)$ for all $n\geq c_2$. We define $O(g(n))$ as the family of functions that grow asymptotically no faster than $g(n)$.
\end{definition}

\begin{definition}[Big-$\Omega$ Notation]
    We $f(n)$ grows asymptotically no slower than $g(n)$ if there exists two positive constants $c_1$ and $c_2$ such that $f(n)\geq c_1 g(n)$ for all $n\geq c_2$. We define $\Omega(g(n))$ as the family of functions that grow asymptotically no slower than $g(n)$.
\end{definition}



\newpage

\section{Distributed Tracking}

Perhaps the most enlightening discovery of prior literature on RTS is the connection to the seemingly remote problem of \textit{Distributed Tracking} \cite{Cormode2011}, also known as \textit{Distributed Monitoring} or \textit{Distributed Functional Monitoring}. A problem of study from Distributed Computing, Distributed Tracking models the following scenario: Consider a coordinator $q$ and a set of participcants $s_1, \dots, s_h$. Each participant has a corresponding counter $c_i$ initialised to 0, and the coordinator has a tolerance $\tau\in\mathbb{N}$. At each time step, at most one of the counters $c_i$ are incremented; that is, one or zero counters increase.  The goal of the Distributed Tracking is for the coordinator to report the instant that 
\begin{align}
    \sum_{i=1}^{h}c_i = \tau
\end{align}
Of course, for $t=1,\dots$ the coordinator can query each participant, assuming $O(1)$ messaging cost, this results in  $\Omega(\tau h)$ messages. The goal of Distributed Tracking is to design an algorithm that minimises such message costs. \\
\\
We consider the following algorithm presented by Cormorde, Muthukrishnan and Yi \cite{Cormode} which solves the distributed tracking problem in $O(h\log \tau)$ messages

%TODO: Finish this! 
\begin{algorithm}
\caption{Distributed Tracking }\label{Algorithm 1}
\begin{algorithmic}
\Require $\tau > 0$
\If{$\tau < 6h$}
    \State \text{solve directly by sending $O(\tau) = O(h)$ messages}
\ElsIf{$\tau \geq 6h$}
    \State \text{assign to each participant a \textit{slack} value of $\lambda = \lfloor\tau/2h \rfloor$} 
    \State \text{for each participant assign counter $\Bar{c_i}\gets 0$ }
    \For{$t = 1,\dots$} \Comment{time steps at which $c_i$ are possibly incremeneted}
        \If{$c_i - \Bar{c_i} = \lambda$}
            \State participant $s_i$ transmits signal
        \EndIf
    \EndFor
\EndIf
\end{algorithmic}
\end{algorithm}


\begin{theorem}[Distributed Tracking is Sub-Quadratic] For a Distributed Tracking instance with $h$ participants and coordinator threshold of $\tau$, maturity can be reported in $O(h\log\tau)$ messages
\end{theorem}
\begin{proof}
    It is clear that $O(h)$ messages are transmitted each round. We now bound the number of rounds that are required by the algorithm. At the conclusion of each round, the working threshold $\tau^\prime$ is reduced by a factor of: 
    \begin{align*}
        \tau^\prime &= \tau - \sum_{i=1}^{h}c_i \\
        &\leq \tau - \sum_{i=1}^{h}\left\lfloor \frac{\tau}{2h}\right\rfloor \\
        &\leq \tau - \sum_{i=1}^{h} \left(\frac{\tau}{2h} - 1\right) \\
        &= \tau - \frac{\tau}{2} + h = \frac{\tau}{2} + h
    \end{align*}
    Using $\tau \leq 6h$ gives
    \begin{align*}
        \frac{\tau}{2} +h &\leq \frac{\tau}{2} + \frac{\tau}{6} \\
        &= \frac{2\tau}{3}
    \end{align*}
    Which implies the working threshold reduces by a factor of $2\tau/3$, using standard analysis techniques for algorithms implies $O(\log \tau)$ rounds. 
\end{proof}


\begin{theorem}[Correctness of Distributed Tracking] Distributed Tracking correctly reports the instant of maturity.
\end{theorem}
\begin{proof}
    
\end{proof}
\todo{finish off proof}


\subsubsection*{Weighted Distributed Tracking}

A slight modification which will be of later importance is to account for counter increments of the form
$$c_i \leftarrow c_i + w \quad w \in \mathbb{N}$$
Note that this results in a modified maturity condition to determining the instant that 
\begin{align}
    \sum_{i=1}^{h}c_i \geq \tau
\end{align}
Of course, one could reduce this to performing $c_i \leftarrow c_i +1$ increments $w$ times, and one can recover Algorithm \ref{Algorithm 1} with unaltered run time. However, if one assumes performing an increment requires $O(1)$ \texttt{CPU} time, this results in $O(\tau + h\log\tau)$ CPU time, which can become unnecessarily slow if $\tau$ is large.
Through slight modification however we can reduce the \texttt{CPU} time to $O(n+h\log\tau)$, where $n$ is the number of increments required for $(2)$ to hold.

\begin{algorithm}
\caption{Integer Distributed Tracking }\label{Algorithm 3}
\begin{algorithmic}
    \If{$\tau \leq 6h$}
        \State solve directly by sending $O(\tau) = O(h)$ messages
    \ElsIf{$\tau > 6h$}
        \State $q$ launches a round by informing $s_i$ of slack $\lambda = \lfloor \tau/2h \rfloor$
        \State assign $\Bar{c}_i \gets 0$ to each participant
        \State after incrementing counters if $c_i - \Bar{c}_i \geq \lambda$
        \begin{enumerate}
            \item $s_i$ sends a signal to $q$ and update $\Bar{c}_i \gets \Bar{c_i} + \lambda$
            \item if $c_i - \Bar{c}_i \geq \lambda$ and $q$ has not anounced the end of the round, repeat from step 1.
        \end{enumerate}
    \EndIf
\end{algorithmic}
\end{algorithm}
By reprising the proof of Theorem 1.1, The algorithm clearly terminates in $O(h\log\tau)$ messages with $O(n + h\log\tau)$ compute. We now close out this section by providing a short proof of correctness for Algorithm 2. 
\begin{theorem}[Correctness] The Integer Distributed Tracking presented correctly reports the instant that $\sum_{i=1}^{h}c_i \geq \tau$
\end{theorem}
\begin{proof}
    If a round still has not finished at the end of a timestamp it must hold that 
    \begin{align*}
        \sum_{i=1}^{h}c_i &\leq \lambda (h-1) + \sum_{i=1}^{h}(c_i - \Bar{c}_i) \\
        &\leq \lambda(h-1) + \lambda h \leq \tau
    \end{align*}
\end{proof}
\todo{flesh out more}


\section{Logarithmic Rebuilding}